from pathlib import Path
import torch
from torch.utils.data import DataLoader, Sampler, BatchSampler, RandomSampler

from torchvision import transforms
from torch.utils.data import Dataset
from randaugment import RandAugmentMC
import numpy as np
import random
from PIL import Image

mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

TRANSFORM = {
    'train': transforms.Compose([
        transforms.Resize([256, 256]),
        transforms.RandomHorizontalFlip(),
        transforms.RandomCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean,std=std)
    ]),
    'test': transforms.Compose([
        transforms.Resize([224, 224]),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean,std=std)
    ]),
    'strong': transforms.Compose([
        transforms.Resize([256, 256]),
        transforms.RandomHorizontalFlip(),
        transforms.RandomCrop(224),
        RandAugmentMC(n=2, m=10),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean,std=std)
    ])
}

def get_all_loaders(args):
    s_name, t_name = args.dataset['domains'][args.source], args.dataset['domains'][args.target]
    root, text_root = Path(args.dataset['path']), Path(args.dataset['text_path'])
    
    s_list_file = text_root / s_name / args.dataset['list']['all']
    s_train_set = ImageList(root, s_list_file, transform=TRANSFORM['train'])
    s_train_loader = get_loader(s_train_set, args.seed, args.bsize, train=True)

    s_test_set = ImageList(root, s_list_file, transform=TRANSFORM['test'])
    s_test_loader = get_loader(s_test_set, args.seed, args.bsize*2, train=False)

    t_train_list_file = text_root / t_name / args.dataset['list'][args.shot]['train']
    t_test_list_file = text_root / t_name / args.dataset['list'][args.shot]['test']
    t_val_list_file = text_root / t_name / args.dataset['list']['val']

    t_labeled_train_set = ImageList(root, t_train_list_file, transform=TRANSFORM['train'])
    t_labeled_train_loader = get_loader(t_labeled_train_set, args.seed, args.bsize, train=True)

    t_labeled_test_set = ImageList(root, t_train_list_file, transform=TRANSFORM['test'])
    t_labeled_test_loader = get_loader(t_labeled_test_set, args.seed, args.bsize, train=False)

    t_unlabeled_train_set = ImageList(root, t_test_list_file, transform=TRANSFORM['train'], strong_transform=TRANSFORM['strong'] if 'CDAC' in args.method else None)
    t_unlabeled_train_loader = get_loader(t_unlabeled_train_set, args.seed, args.bsize, train=True)
    
    t_unlabeled_test_set = ImageList(root, t_test_list_file, transform=TRANSFORM['test'])
    t_unlabeled_test_loader = get_loader(t_unlabeled_test_set, args.seed, args.bsize*2, train=False)

    t_val_set = ImageList(root, t_val_list_file, transform=TRANSFORM['test'])
    t_val_loader = get_loader(t_val_set, args.seed, args.bsize, train=False)

    return s_train_loader, s_test_loader, t_labeled_train_loader, t_labeled_test_loader, t_unlabeled_train_loader, t_unlabeled_test_loader, t_val_loader

def pil_loader(path: str):
    with open(path, 'rb') as f:
        img = Image.open(f)
        return img.convert('RGB')

def seed_worker(worker_id):
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)

def get_generator(seed):
    g = torch.Generator()
    g.manual_seed(seed)
    return g

def get_loader(dset, seed=None, bsize=24, train=True):
    g = get_generator(seed)
    if train:
        dloader = InfiniteDataLoader(dset,
            batch_size = bsize,
            worker_init_fn=seed_worker, generator=g,
            drop_last=True, num_workers=4)
    else:
        dloader = DataLoader(dset, 
            batch_size = bsize,
            worker_init_fn=seed_worker, generator=g, 
            shuffle=False, drop_last=False, num_workers=4, pin_memory=True)
    return dloader

class ImageList(Dataset):
    def __init__(self, root, list_file, transform, strong_transform=None):
        with (root / list_file).open('r') as f:
            paths = [p[:-1].split() for p in f.readlines()]
        self.imgs = [(root / p, int(l)) for p, l in paths]
        self.transform = transform
        self.strong_transform = strong_transform
    def __len__(self):
        return len(self.imgs)
    def __getitem__(self, idx):
        path, label = self.imgs[idx]
        img = pil_loader(path)
        if self.strong_transform:
            img1 = self.strong_transform(img)
            img2 = self.strong_transform(img)
            return self.transform(img), label, img1, img2, idx
        return self.transform(img), label, idx

class _InfiniteSampler(Sampler):
    """Wraps another Sampler to yield an infinite stream."""
    def __init__(self, sampler):
        self.sampler = sampler

    def __iter__(self):
        while True:
            for batch in self.sampler:
                yield batch

class InfiniteDataLoader:
    def __init__(self, dataset, batch_size, 
                 worker_init_fn=None, 
                 generator=None, drop_last=True, 
                 num_workers=4):
        
        sampler = RandomSampler(dataset, replacement=False, generator=generator)
        batch_sampler = BatchSampler(sampler, batch_size=batch_size, drop_last=drop_last)

        self._infinite_iterator = iter(DataLoader(
            dataset,
            num_workers=num_workers,
            batch_sampler=_InfiniteSampler(batch_sampler),
            worker_init_fn=worker_init_fn
        ))

    def __iter__(self):
        while True:
            yield next(self._infinite_iterator)

    def __len__(self):
        return 0
